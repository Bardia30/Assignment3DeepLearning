{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "$$\n",
    "\\newcommand{\\mat}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\mattr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\matinv}[1]{\\boldsymbol {#1}^{-1}}\n",
    "\\newcommand{\\vec}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\vectr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\rvar}[1]{\\mathrm {#1}}\n",
    "\\newcommand{\\rvec}[1]{\\boldsymbol{\\mathrm{#1}}}\n",
    "\\newcommand{\\diag}{\\mathop{\\mathrm {diag}}}\n",
    "\\newcommand{\\set}[1]{\\mathbb {#1}}\n",
    "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "\\newcommand{\\pderiv}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\bb}[1]{\\boldsymbol{#1}}\n",
    "$$\n",
    "# Part 4: Convolutional Neural Networks\n",
    "<a id=part4></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this part we will explore convolution networks. We'll implement a common block-based deep CNN pattern with an without residual connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-28T21:38:20.378782Z",
     "iopub.status.busy": "2022-04-28T21:38:20.378516Z",
     "iopub.status.idle": "2022-04-28T21:38:21.882803Z",
     "shell.execute_reply": "2022-04-28T21:38:21.882493Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import unittest\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as tvtf\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-28T21:38:21.885185Z",
     "iopub.status.busy": "2022-04-28T21:38:21.885066Z",
     "iopub.status.idle": "2022-04-28T21:38:21.901532Z",
     "shell.execute_reply": "2022-04-28T21:38:21.901217Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "test = unittest.TestCase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: False\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "\n",
    "# If CUDA is available, print additional details\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"Current Device:\", torch.cuda.current_device())\n",
    "    print(\"Device Name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "#I have an Apple Mac Mini M2 which uses Metal Performance Shaders (MPS) for GPU\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use Metal (MPS) on Apple Silicon\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Fall back to CPU\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Reminder: Convolutional layers and networks\n",
    "<a id=part3_1></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Convolutional layers are the most essential building blocks of the state of the art deep learning image classification models and also play an important role in many other tasks.\n",
    "As we saw in the tutorial, when applied to images, convolutional layers operate on and produce volumes (3D tensors) of activations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A convenient way to interpret convolutional layers for images is as a collection of 3D learnable filters,\n",
    "each of which operates on a small spatial region of the input volume.\n",
    "Each filter is convolved with the input volume (\"slides over it\"),\n",
    "and a dot product is computed at each location followed by a non-linearity which produces one activation.\n",
    "All these activations produce a 2D plane known as a **feature map**.\n",
    "Multiple feature maps (one for each filter) comprise the output volume.\n",
    "\n",
    "<img src=\"imgs/cnn_filters.png\" width=\"600\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A crucial property of convolutional layers is their translation equivariance, i.e. shifting the input results in\n",
    "and equivalently shifted output.\n",
    "This produces the ability to detect features regardless of their spatial location in the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Convolutional network architectures usually follow a pattern basic repeating blocks: one or more convolution layers, each followed by a non-linearity (generally ReLU) and then a pooling layer to reduce spatial dimensions. Usually, the number of convolutional filters increases the deeper they are in the network.\n",
    "These layers are meant to extract features from the input.\n",
    "Then, one or more fully-connected layers is used to combine the extracted features into the required number of output class scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Building convolutional networks with PyTorch\n",
    "<a id=part3_2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "PyTorch provides all the basic building blocks needed for creating a convolutional arcitecture within the [`torch.nn`](https://pytorch.org/docs/stable/nn.html) package.\n",
    "Let's use them to create a basic convolutional network with the following architecture pattern:\n",
    "\n",
    "    [(CONV -> ACT)*P -> POOL]*(N/P) -> (FC -> ACT)*M -> FC\n",
    "\n",
    "Here $N$ is the total number of convolutional layers,\n",
    "$P$ specifies how many convolutions to perform before each pooling layer\n",
    "and $M$ specifies the number of hidden fully-connected layers before the final output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**TODO**: Complete the implementaion of the `CNN` class in the `hw3/cnn.py` module.\n",
    "Use PyTorch's `nn.Conv2d` and `nn.MaxPool2d` for the convolution and pooling layers.\n",
    "It's recommended to implement the missing functionality in the order of the class' methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-28T21:38:21.903703Z",
     "iopub.status.busy": "2022-04-28T21:38:21.903596Z",
     "iopub.status.idle": "2022-04-28T21:38:22.000758Z",
     "shell.execute_reply": "2022-04-28T21:38:22.000357Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== test i=0 ===\n",
      "CNN(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU()\n",
      "    (7): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU()\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=20000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "test_out=tensor([[ 0.0745, -0.1058,  0.0928,  0.0476,  0.0057,  0.0051,  0.0938, -0.0582,\n",
      "          0.0573,  0.0583]], grad_fn=<AddmmBackward0>)\n",
      "max_diff=7.450580596923828e-09\n",
      "\n",
      "=== test i=1 ===\n",
      "CNN(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2), padding=(3, 3))\n",
      "    (1): LeakyReLU(negative_slope=0.05)\n",
      "    (2): Conv2d(32, 32, kernel_size=(5, 5), stride=(2, 2), padding=(3, 3))\n",
      "    (3): LeakyReLU(negative_slope=0.05)\n",
      "    (4): AvgPool2d(kernel_size=3, stride=3, padding=0)\n",
      "    (5): Conv2d(32, 32, kernel_size=(5, 5), stride=(2, 2), padding=(3, 3))\n",
      "    (6): LeakyReLU(negative_slope=0.05)\n",
      "    (7): Conv2d(32, 32, kernel_size=(5, 5), stride=(2, 2), padding=(3, 3))\n",
      "    (8): LeakyReLU(negative_slope=0.05)\n",
      "    (9): AvgPool2d(kernel_size=3, stride=3, padding=0)\n",
      "  )\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=100, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.05)\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.05)\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "test_out=tensor([[ 0.0724, -0.0030,  0.0637, -0.0073,  0.0932, -0.0662, -0.0656,  0.0076,\n",
      "          0.0193,  0.0241]], grad_fn=<AddmmBackward0>)\n",
      "max_diff=1.1175870895385742e-08\n",
      "\n",
      "=== test i=2 ===\n",
      "CNN(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.1)\n",
      "    (2): Conv2d(16, 16, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "    (3): LeakyReLU(negative_slope=0.1)\n",
      "    (4): Conv2d(16, 16, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "    (5): LeakyReLU(negative_slope=0.1)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(16, 16, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "    (8): LeakyReLU(negative_slope=0.1)\n",
      "    (9): Conv2d(16, 16, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "    (10): LeakyReLU(negative_slope=0.1)\n",
      "  )\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=100, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.1)\n",
      "    (2): Linear(in_features=100, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "test_out=tensor([[-0.0004, -0.0094,  0.0817]], grad_fn=<AddmmBackward0>)\n",
      "max_diff=1.862645149230957e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tx/l6jnnmt13x50_18kqr2h63080000gn/T/ipykernel_55545/3003510923.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  expected_out = torch.load(f'tests/assets/expected_conv_out_{i:02d}.pt')\n"
     ]
    }
   ],
   "source": [
    "from hw3.cnn import CNN\n",
    "\n",
    "test_params = [\n",
    "    dict(\n",
    "        in_size=(3,100,100), out_classes=10,\n",
    "        channels=[32]*4, pool_every=2, hidden_dims=[100]*2,\n",
    "        conv_params=dict(kernel_size=3, stride=1, padding=1),\n",
    "        activation_type='relu', activation_params=dict(),\n",
    "        pooling_type='max', pooling_params=dict(kernel_size=2),\n",
    "    ),\n",
    "    dict(\n",
    "        in_size=(3,100,100), out_classes=10,\n",
    "        channels=[32]*4, pool_every=2, hidden_dims=[100]*2,\n",
    "        conv_params=dict(kernel_size=5, stride=2, padding=3),\n",
    "        activation_type='lrelu', activation_params=dict(negative_slope=0.05),\n",
    "        pooling_type='avg', pooling_params=dict(kernel_size=3),\n",
    "    ),\n",
    "    dict(\n",
    "        in_size=(3,100,100), out_classes=3,\n",
    "        channels=[16]*5, pool_every=3, hidden_dims=[100]*1,\n",
    "        conv_params=dict(kernel_size=2, stride=2, padding=2),\n",
    "        activation_type='lrelu', activation_params=dict(negative_slope=0.1),\n",
    "        pooling_type='max', pooling_params=dict(kernel_size=2),\n",
    "    ),\n",
    "]\n",
    "\n",
    "for i, params in enumerate(test_params):\n",
    "    torch.manual_seed(seed)\n",
    "    net = CNN(**params)\n",
    "    print(f\"\\n=== test {i=} ===\")\n",
    "    print(net)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    test_out = net(torch.ones(1, 3, 100, 100))\n",
    "    print(f'{test_out=}')\n",
    "\n",
    "    expected_out = torch.load(f'tests/assets/expected_conv_out_{i:02d}.pt')\n",
    "    print(f'max_diff={torch.max(torch.abs(test_out - expected_out)).item()}')\n",
    "    test.assertTrue(torch.allclose(test_out, expected_out, atol=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As before, we'll wrap our model with a `Classifier` that provides the necessary functionality for calculating probability scores and obtaining class label predictions.\n",
    "This time, we'll use a simple approach that simply selects the class with the highest score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**TODO**: Implement the `ArgMaxClassifier` in the `hw3/classifier.py` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-28T21:38:22.003651Z",
     "iopub.status.busy": "2022-04-28T21:38:22.003392Z",
     "iopub.status.idle": "2022-04-28T21:38:22.281658Z",
     "shell.execute_reply": "2022-04-28T21:38:22.281253Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from hw3.classifier import ArgMaxClassifier\n",
    "\n",
    "model = ArgMaxClassifier(model=CNN(**test_params[0]))\n",
    "\n",
    "test_image = torch.randint(low=0, high=256, size=(3, 100, 100), dtype=torch.float).unsqueeze(0)\n",
    "test.assertEqual(model.classify(test_image).shape, (1,))\n",
    "test.assertEqual(model.predict_proba(test_image).shape, (1, 10))\n",
    "test.assertAlmostEqual(torch.sum(model.predict_proba(test_image)).item(), 1.0, delta=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's now load CIFAR-10 to use as our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-28T21:38:22.283880Z",
     "iopub.status.busy": "2022-04-28T21:38:22.283744Z",
     "iopub.status.idle": "2022-04-28T21:38:23.839965Z",
     "shell.execute_reply": "2022-04-28T21:38:23.839646Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train: 50000 samples\n",
      "Test: 10000 samples\n",
      "input image size = torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.expanduser('~/.pytorch-datasets')\n",
    "ds_train = torchvision.datasets.CIFAR10(root=data_dir, download=True, train=True, transform=tvtf.ToTensor())\n",
    "ds_test = torchvision.datasets.CIFAR10(root=data_dir, download=True, train=False, transform=tvtf.ToTensor())\n",
    "\n",
    "print(f'Train: {len(ds_train)} samples')\n",
    "print(f'Test: {len(ds_test)} samples')\n",
    "\n",
    "x0,_ = ds_train[0]\n",
    "in_size = x0.shape\n",
    "num_classes = 10\n",
    "print('input image size =', in_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now as usual, as a sanity test let's make sure we can overfit a tiny dataset with our model. But first we need to adapt our `Trainer` for PyTorch models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**TODO**:\n",
    "1. Complete the implementaion of the `ClassifierTrainer` class in the `hw3/training.py` module if you haven't done so already.\n",
    "2. Set the optimizer hyperparameters in `part4_optim_hp()`, respectively, in `hw3/answers.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-28T21:38:23.841888Z",
     "iopub.status.busy": "2022-04-28T21:38:23.841773Z",
     "iopub.status.idle": "2022-04-28T21:38:28.567938Z",
     "shell.execute_reply": "2022-04-28T21:38:28.567545Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd86d405dcf482b94678fa758221dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_batch:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712f852f92c94061b9c6baa1544c1163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_batch:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0633af4c1b03470c9aac8cd6bbddad48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_batch:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72338dde0a9741289f77668061f8e786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_batch:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96e9cb6dac94943857fd21188c1a5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_batch:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hw3.training import ClassifierTrainer\n",
    "from hw3.answers import part4_optim_hp\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Define a tiny part of the CIFAR-10 dataset to overfit it\n",
    "batch_size = 2\n",
    "max_batches = 25\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size, shuffle=False)\n",
    "\n",
    "# Create model, loss and optimizer instances\n",
    "model = ArgMaxClassifier(\n",
    "    model=CNN(\n",
    "        in_size, num_classes, channels=[32], pool_every=1, hidden_dims=[100],\n",
    "        conv_params=dict(kernel_size=3, stride=1, padding=1),\n",
    "        pooling_params=dict(kernel_size=2),\n",
    "    )\n",
    ")\n",
    "\n",
    "hp_optim = part4_optim_hp()\n",
    "loss_fn = hp_optim.pop('loss_fn')\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), **hp_optim)\n",
    "\n",
    "# Use ClassifierTrainer to run only the training loop a few times.\n",
    "trainer = ClassifierTrainer(model, loss_fn, optimizer, device)\n",
    "best_acc = 0\n",
    "for i in range(25):\n",
    "    res = trainer.train_epoch(dl_train, max_batches=max_batches, verbose=(i%5==0))\n",
    "    best_acc = res.accuracy if res.accuracy > best_acc else best_acc\n",
    "    \n",
    "# Test overfitting\n",
    "test.assertGreaterEqual(best_acc, 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Residual Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A very common addition to the basic convolutional architecture described above are **shortcut connections**.\n",
    "First proposed by [He et al. (2016)](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf), this simple addition has been shown to be a crucial\n",
    "ingredient in order to achieve effective learning with very deep networks.\n",
    "Virtually all state of the art image classification models from recent years use this technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The idea is to add a shortcut, or skip, around every two or more convolutional layers:\n",
    "\n",
    "<img src=\"imgs/resnet_block2.png\" width=\"700\" />\n",
    "\n",
    "**On the left** we see an example of a regular Residual Block, that takes a 64 channel input, and performs two 3X3 convolutions , which are added to the original input.  \n",
    "**On the right** we see an exapmle of a Bottleneck Residual Block, that takes a 256 channel input, projects it to a 64 channel tensor with a 1X1 convolution, then performs an inner 3X3 convolution, followd by another 1X1 projection convolution back to the original numer of channels, 256. The output is then added to the original input.\n",
    "\n",
    "Overall, we can denote the structure of the bottleneck channels in the given example as 256->64->64->256, where the first and last arrows denote the 1X1 convolutions, and the middle arrow is the inner convolution.\n",
    "Note that the 1X1 convolution with the default parameters (in pytorch) is defined such that the only dimension of the tensor that changes is the number of channels.\n",
    "\n",
    "This adds an easy way for the network to learn identity mappings: set the weight values to be very small.\n",
    "The outcome is that the convolutional layers learn a **residual** mapping, i.e. some delta that is applied\n",
    "to the identity map, instead of actually learning a completely new mapping from scratch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Lets start by implementing a general residual block, representing a structure similar to the above diagrams.\n",
    "Our residual block will be composed of:\n",
    "- A \"main path\" with some number of convolutional layers with ReLU between them. Optionally, we'll also apply dropout and  batch normalization layers (in this order) between the convolutions, before the ReLU.\n",
    "- A \"shortcut path\" implementing an identity mapping around the main path. In case of a different number of input/output channels, the shortcut path should contain an additional `1x1` convolution to project the channel dimension.\n",
    "- The sum of the main and shortcut paths output is passed though a ReLU and returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**TODO**: Complete the implementation of the `ResidualBlock`'s `__init__()` method in the `hw3/cnn.py` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-28T21:38:28.570466Z",
     "iopub.status.busy": "2022-04-28T21:38:28.570324Z",
     "iopub.status.idle": "2022-04-28T21:38:28.605315Z",
     "shell.execute_reply": "2022-04-28T21:38:28.605004Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResidualBlock(\n",
      "  (main_path): Sequential(\n",
      "    (0): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout2d(p=0.2, inplace=False)\n",
      "    (4): Conv2d(6, 4, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout2d(p=0.2, inplace=False)\n",
      "    (8): Conv2d(4, 4, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (9): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout2d(p=0.2, inplace=False)\n",
      "    (12): Conv2d(4, 4, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (shortcut_path): Conv2d(3, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      ")\n",
      "Main Path Output Mean: 0.029574673622846603, Std: 0.25415530800819397\n",
      "Shortcut Path Output Mean: 0.0989692285656929, Std: 0.5561443567276001\n",
      "Combined Output Mean (before ReLU): 0.1285439431667328, Std: 0.6580609679222107\n",
      "Final Output Mean (after ReLU): 0.355817049741745, Std: 0.3388625383377075\n",
      "test_out.shape=torch.Size([1, 4, 32, 32])\n",
      "max_diff=1.9073693752288818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tx/l6jnnmt13x50_18kqr2h63080000gn/T/ipykernel_55545/3959498997.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  expected_out = torch.load('tests/assets/expected_resblock_out.pt')\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Max diff 1.9073693752288818 exceeds tolerance!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m max_diff \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(torch\u001b[38;5;241m.\u001b[39mabs(test_out \u001b[38;5;241m-\u001b[39m expected_out))\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_diff=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_diff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(test_out, expected_out, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax diff \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_diff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m exceeds tolerance!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Max diff 1.9073693752288818 exceeds tolerance!"
     ]
    }
   ],
   "source": [
    "from hw3.cnn import ResidualBlock\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "resblock = ResidualBlock(\n",
    "    in_channels=3, channels=[6, 4]*2, kernel_sizes=[3, 5]*2,\n",
    "    batchnorm=True, dropout=0.2\n",
    ")\n",
    "print(resblock)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "test_out = resblock(torch.ones(1, 3, 32, 32))\n",
    "print(f'{test_out.shape=}')\n",
    "\n",
    "expected_out = torch.load('tests/assets/expected_resblock_out.pt')\n",
    "print(f'max_diff={torch.max(torch.abs(test_out - expected_out)).item()}')\n",
    "test.assertTrue(torch.allclose(test_out, expected_out, atol=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "#### Bottleneck Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the ResNet Block diagram shown above, the right block is called a bottleneck block.\n",
    "This type of block is mainly used deep in the network, where the feature space becomes increasingly high-dimensional (i.e. there are many channels).\n",
    "\n",
    "Instead of applying a KxK conv layer on the original input channels, a bottleneck block\n",
    "first projects to a lower number of features (channels), applies the KxK conv on the result, and then projects back to the original feature space.\n",
    "Both projections are performed with 1x1 convolutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**TODO**: Complete the implementation of the `ResidualBottleneckBlock` in the `hw3/cnn.py` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-28T21:38:28.607405Z",
     "iopub.status.busy": "2022-04-28T21:38:28.607293Z",
     "iopub.status.idle": "2022-04-28T21:38:28.659720Z",
     "shell.execute_reply": "2022-04-28T21:38:28.659411Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResidualBottleneckBlock(\n",
      "  (main_path): Sequential(\n",
      "    (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Dropout2d(p=0.1, inplace=False)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): LeakyReLU(negative_slope=0.01)\n",
      "    (5): Dropout2d(p=0.1, inplace=False)\n",
      "    (6): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (7): LeakyReLU(negative_slope=0.01)\n",
      "    (8): Dropout2d(p=0.1, inplace=False)\n",
      "    (9): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): LeakyReLU(negative_slope=0.01)\n",
      "    (11): Dropout2d(p=0.1, inplace=False)\n",
      "    (12): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (13): LeakyReLU(negative_slope=0.01)\n",
      "    (14): Dropout2d(p=0.1, inplace=False)\n",
      "    (15): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (shortcut_path): Identity()\n",
      ")\n",
      "Main Path Output Mean: -0.0015658539487048984, Std: 0.04946903511881828\n",
      "Shortcut Path Output Mean: 1.0, Std: 0.0\n",
      "Combined Output Mean (before ReLU): 0.9984341859817505, Std: 0.049469031393527985\n",
      "Final Output Mean (after ReLU): 0.9984341859817505, Std: 0.049469031393527985\n",
      "test_out.shape=torch.Size([1, 256, 32, 32])\n",
      "max_diff=0.26273059844970703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tx/l6jnnmt13x50_18kqr2h63080000gn/T/ipykernel_55545/576432873.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  expected_out = torch.load('tests/assets/expected_resblock_bn_out.pt')\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "False is not true",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m expected_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtests/assets/expected_resblock_bn_out.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_diff=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mmax(torch\u001b[38;5;241m.\u001b[39mabs(test_out\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mexpected_out))\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massertTrue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/unittest/case.py:727\u001b[0m, in \u001b[0;36mTestCase.assertTrue\u001b[0;34m(self, expr, msg)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m expr:\n\u001b[1;32m    726\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_formatMessage(msg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not true\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m safe_repr(expr))\n\u001b[0;32m--> 727\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfailureException(msg)\n",
      "\u001b[0;31mAssertionError\u001b[0m: False is not true"
     ]
    }
   ],
   "source": [
    "from hw3.cnn import ResidualBottleneckBlock\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "resblock_bn = ResidualBottleneckBlock(\n",
    "    in_out_channels=256, inner_channels=[64, 32, 64], inner_kernel_sizes=[3, 5, 3],\n",
    "    batchnorm=False, dropout=0.1, activation_type=\"lrelu\"\n",
    ")\n",
    "print(resblock_bn)\n",
    "\n",
    "# Test a forward pass\n",
    "torch.manual_seed(seed)\n",
    "test_in  = torch.ones(1, 256, 32, 32)\n",
    "test_out = resblock_bn(test_in)\n",
    "print(f'{test_out.shape=}')\n",
    "assert test_out.shape == test_in.shape \n",
    "\n",
    "expected_out = torch.load('tests/assets/expected_resblock_bn_out.pt')\n",
    "print(f'max_diff={torch.max(torch.abs(test_out - expected_out)).item()}')\n",
    "test.assertTrue(torch.allclose(test_out, expected_out, atol=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, based on the `ResidualBlock`, we'll implement our own variation of a residual network (ResNet),\n",
    "with the following architecture:\n",
    "\n",
    "    [-> (CONV -> ACT)*P -> POOL]*(N/P) -> (FC -> ACT)*M -> FC\n",
    "     \\------- SKIP ------/\n",
    "     \n",
    "Note that $N$, $P$ and $M$ are as before, however now $P$ also controls the number of convolutional layers to add a skip-connection to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**TODO**: Complete the implementation of the `ResNet` class in the `hw3/cnn.py` module.\n",
    "You must use your `ResidualBlock`s or `ResidualBottleneckBlock`s to group together every $P$ convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-28T21:38:28.661659Z",
     "iopub.status.busy": "2022-04-28T21:38:28.661551Z",
     "iopub.status.idle": "2022-04-28T21:38:28.889340Z",
     "shell.execute_reply": "2022-04-28T21:38:28.889032Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Path Output Mean: 0.00021750903397332877, Std: 0.023202840238809586\n",
      "Shortcut Path Output Mean: 0.0, Std: 0.0\n",
      "Combined Output Mean (before ReLU): 0.00021750903397332877, Std: 0.023202840238809586\n",
      "Final Output Mean (after ReLU): 0.010025519877672195, Std: 0.013569045811891556\n",
      "Main Path Output Mean: -0.016078632324934006, Std: 0.4018626809120178\n",
      "Shortcut Path Output Mean: 0.010025519877672195, Std: 0.013569077476859093\n",
      "Combined Output Mean (before ReLU): -0.0060531143099069595, Std: 0.40195101499557495\n",
      "Final Output Mean (after ReLU): 0.09943467378616333, Std: 0.25377708673477173\n",
      "\n",
      "=== test i=0 ===\n",
      "ResNet(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (main_path): Sequential(\n",
      "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.01)\n",
      "        (3): Dropout2d(p=0.1, inplace=False)\n",
      "        (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): LeakyReLU(negative_slope=0.01)\n",
      "        (7): Dropout2d(p=0.1, inplace=False)\n",
      "        (8): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (10): LeakyReLU(negative_slope=0.01)\n",
      "        (11): Dropout2d(p=0.1, inplace=False)\n",
      "        (12): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (14): LeakyReLU(negative_slope=0.01)\n",
      "        (15): Dropout2d(p=0.1, inplace=False)\n",
      "        (16): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (shortcut_path): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (2): ResidualBlock(\n",
      "      (main_path): Sequential(\n",
      "        (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.01)\n",
      "        (3): Dropout2d(p=0.1, inplace=False)\n",
      "        (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): LeakyReLU(negative_slope=0.01)\n",
      "        (7): Dropout2d(p=0.1, inplace=False)\n",
      "        (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (shortcut_path): Identity()\n",
      "    )\n",
      "  )\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=160000, out_features=100, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Main Path Output Mean: 0.025117866694927216, Std: 0.4377259910106659\n",
      "Shortcut Path Output Mean: -0.16252653300762177, Std: 0.5178042650222778\n",
      "Combined Output Mean (before ReLU): -0.13740870356559753, Std: 0.6617247462272644\n",
      "Final Output Mean (after ReLU): 0.1803063452243805, Std: 0.3714827597141266\n",
      "Main Path Output Mean: -0.017590327188372612, Std: 0.44327571988105774\n",
      "Shortcut Path Output Mean: 0.18030637502670288, Std: 0.3356834948062897\n",
      "Combined Output Mean (before ReLU): 0.16271604597568512, Std: 0.5419476628303528\n",
      "Final Output Mean (after ReLU): 0.25335004925727844, Std: 0.4269914925098419\n",
      "test_out=tensor([[-0.0635, -0.0184,  0.0855, -0.0510, -0.0951, -0.1364,  0.0297,  0.0039,\n",
      "          0.1358, -0.0770]], grad_fn=<AddmmBackward0>)\n",
      "max_diff=0.0\n",
      "Main Path Output Mean: -0.019814174622297287, Std: 0.23281723260879517\n",
      "Shortcut Path Output Mean: 0.0, Std: 0.0\n",
      "Combined Output Mean (before ReLU): -0.019814174622297287, Std: 0.23281723260879517\n",
      "Final Output Mean (after ReLU): 0.09367864578962326, Std: 0.084719218313694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of hw3.cnn failed: Traceback (most recent call last):\n",
      "  File \"/Users/bardiadehbasti/Library/Python/3.12/lib/python/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/bardiadehbasti/Library/Python/3.12/lib/python/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/Users/bardiadehbasti/Library/Python/3.12/lib/python/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/Users/bardiadehbasti/Library/Python/3.12/lib/python/site-packages/IPython/extensions/autoreload.py\", line 349, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bardiadehbasti/Library/Python/3.12/lib/python/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/Users/bardiadehbasti/Library/Python/3.12/lib/python/site-packages/IPython/extensions/autoreload.py\", line 309, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: __init__() requires a code object with 0 free vars, not 1\n",
      "]\n",
      "/var/folders/tx/l6jnnmt13x50_18kqr2h63080000gn/T/ipykernel_55545/581427581.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  expected_out = torch.load(f'tests/assets/expected_resnet_out_{i:02d}.pt')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [16, 64, 1, 1], expected input[1, 3, 50, 50] to have 64 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, params \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_params):\n\u001b[1;32m     24\u001b[0m     torch\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[0;32m---> 25\u001b[0m     net \u001b[38;5;241m=\u001b[39m \u001b[43mResNet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== test \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(net)\n",
      "File \u001b[0;32m~/Documents/MEng(AI)/DeepLearning/Assignment3/hw3/cnn.py:327\u001b[0m, in \u001b[0;36mResNet.__init__\u001b[0;34m(self, in_size, out_classes, channels, pool_every, hidden_dims, batchnorm, dropout, bottleneck, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m dropout\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbottleneck \u001b[38;5;241m=\u001b[39m bottleneck\n\u001b[0;32m--> 327\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MEng(AI)/DeepLearning/Assignment3/hw3/cnn.py:78\u001b[0m, in \u001b[0;36mCNN.__init__\u001b[0;34m(self, in_size, out_classes, channels, pool_every, hidden_dims, conv_params, activation_type, activation_params, pooling_type, pooling_params)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported activation or pooling type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_extractor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_feature_extractor()\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_mlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MEng(AI)/DeepLearning/Assignment3/hw3/cnn.py:146\u001b[0m, in \u001b[0;36mCNN._make_mlp\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m mlp: MLP \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# ====== YOUR CODE: ======\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m dims \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dims) \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_classes]\n\u001b[1;32m    147\u001b[0m layers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m in_dim, out_dim \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(dims[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dims[\u001b[38;5;241m1\u001b[39m:]):\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;66;03m# Add linear (fully connected) layer\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/MEng(AI)/DeepLearning/Assignment3/hw3/cnn.py:127\u001b[0m, in \u001b[0;36mCNN._n_features\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m# ====== YOUR CODE: ======\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     dummy_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_size)  \u001b[38;5;66;03m# Dummy input\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m features\u001b[38;5;241m.\u001b[39mview(features\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten and get size\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;66;03m# ========================\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/MEng(AI)/DeepLearning/Assignment3/hw3/cnn.py:249\u001b[0m, in \u001b[0;36mResidualBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor):\n\u001b[0;32m--> 249\u001b[0m     main_path_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m     shortcut_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshortcut_path(x)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMain Path Output Mean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmain_path_out\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Std: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmain_path_out\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 64, 1, 1], expected input[1, 3, 50, 50] to have 64 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "from hw3.cnn import ResNet\n",
    "\n",
    "test_params = [\n",
    "    dict(\n",
    "        in_size=(3,100,100), out_classes=10, channels=[32, 64]*3,\n",
    "        pool_every=4, hidden_dims=[100]*2,\n",
    "        activation_type='lrelu', activation_params=dict(negative_slope=0.01),\n",
    "        pooling_type='avg', pooling_params=dict(kernel_size=2),\n",
    "        batchnorm=True, dropout=0.1,\n",
    "        bottleneck=False\n",
    "    ),\n",
    "    dict(\n",
    "        # create 64->16->64 bottlenecks\n",
    "        in_size=(3,100,100), out_classes=5, channels=[64, 16, 64]*4,\n",
    "        pool_every=3, hidden_dims=[64]*1,\n",
    "        activation_type='tanh',\n",
    "        pooling_type='max', pooling_params=dict(kernel_size=2),\n",
    "        batchnorm=True, dropout=0.1,\n",
    "        bottleneck=True\n",
    "    )\n",
    "]\n",
    "\n",
    "for i, params in enumerate(test_params):\n",
    "    torch.manual_seed(seed)\n",
    "    net = ResNet(**params)\n",
    "    print(f\"\\n=== test {i=} ===\")\n",
    "    print(net)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    test_out = net(torch.ones(1, 3, 100, 100))\n",
    "    print(f'{test_out=}')\n",
    "    \n",
    "    expected_out = torch.load(f'tests/assets/expected_resnet_out_{i:02d}.pt')\n",
    "    print(f'max_diff={torch.max(torch.abs(test_out - expected_out)).item()}')\n",
    "    test.assertTrue(torch.allclose(test_out, expected_out, atol=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Questions\n",
    "<a id=part3_4></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**TODO** Answer the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Question 1\n",
    "\n",
    "Consider the bottleneck block from the right side of the ResNet diagram above.\n",
    "Compare it to a regular block that performs a two 3x3 convs directly on the 256-channel input (i.e. as shown in the left side of the diagram, with a different number of channels).\n",
    "Explain the differences between the regular block and the bottleneck block in terms of:\n",
    "\n",
    "1. Number of parameters. Calculate the exact numbers for these two examples.\n",
    "2. Number of floating point operations required to compute an output (qualitative assessment).\n",
    "3. Ability to combine the input: (1) spatially (within feature maps); (2) across feature maps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Comparing Regular Block and Bottleneck Block\n",
    "\n",
    "#### **1. Number of Parameters**\n",
    "\n",
    "**Regular Block**:\n",
    "- Each 3x3 convolution in the regular block processes 256 input channels and outputs 256 channels.  \n",
    "  - First 3x3 conv: \\(256 \\times 256 \\times 3 \\times 3 + 256 = 590,080\\) parameters.  \n",
    "  - Second 3x3 conv: Same as above, \\(590,080\\) parameters.  \n",
    "  - **Total**: \\(590,080 + 590,080 = 1,180,160\\) parameters.\n",
    "\n",
    "**Bottleneck Block**:\n",
    "- First 1x1 conv reduces dimensions to 64:  \n",
    "  \\(256 \\times 64 \\times 1 \\times 1 + 64 = 16,448\\) parameters.  \n",
    "- Middle 3x3 conv processes 64 channels:  \n",
    "  \\(64 \\times 64 \\times 3 \\times 3 + 64 = 36,928\\) parameters.  \n",
    "- Last 1x1 conv restores dimensions to 256:  \n",
    "  \\(64 \\times 256 \\times 1 \\times 1 + 256 = 16,640\\) parameters.  \n",
    "- **Total**: \\(16,448 + 36,928 + 16,640 = 70,016\\) parameters.\n",
    "\n",
    "**Comparison**:\n",
    "The bottleneck block has significantly fewer parameters (\\(70,016\\)) compared to the regular block (\\(1,180,160\\)).\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Number of Floating Point Operations (FLOPs)**\n",
    "\n",
    "**Regular Block**:\n",
    "- Each 3x3 convolution involves:  \n",
    "  \\(H \\times W \\times \\text{Input Channels} \\times \\text{Output Channels} \\times 3 \\times 3\\).  \n",
    "- For an input size of \\(56 \\times 56\\):  \n",
    "  - First conv FLOPs: \\(56 \\times 56 \\times 256 \\times 256 \\times 9 = 18,475,008\\).  \n",
    "  - Second conv FLOPs: Same as above.  \n",
    "  - **Total**: \\(18,475,008 + 18,475,008 = 36,950,016\\).\n",
    "\n",
    "**Bottleneck Block**:\n",
    "- First 1x1 conv FLOPs:  \n",
    "  \\(56 \\times 56 \\times 256 \\times 64 = 917,504\\).  \n",
    "- Middle 3x3 conv FLOPs:  \n",
    "  \\(56 \\times 56 \\times 64 \\times 64 \\times 9 = 1,835,008\\).  \n",
    "- Last 1x1 conv FLOPs:  \n",
    "  \\(56 \\times 56 \\times 64 \\times 256 = 917,504\\).  \n",
    "- **Total**: \\(917,504 + 1,835,008 + 917,504 = 3,670,016\\).\n",
    "\n",
    "**Comparison**:\n",
    "The bottleneck block requires far fewer FLOPs (\\(3,670,016\\)) compared to the regular block (\\(36,950,016\\)).\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Ability to Combine Inputs**### Question 1: Comparing Regular Block and Bottleneck Block\n",
    "\n",
    "#### **1. Number of Parameters**\n",
    "\n",
    "**Regular Block**:\n",
    "- Each 3x3 convolution in the regular block processes 256 input channels and outputs 256 channels.  \n",
    "  - First 3x3 conv: \\(256 * 256 * 3 * 3 + 256 = 590,080\\) parameters.  \n",
    "  - Second 3x3 conv: Same as above, \\(590,080\\) parameters.  \n",
    "  - **Total**: \\(590,080 + 590,080 = 1,180,160\\) parameters.\n",
    "\n",
    "**Bottleneck Block**:\n",
    "- First 1x1 conv reduces dimensions to 64:  \n",
    "  \\(256 * 64 * 1 * 1 + 64 = 16,448\\) parameters.  \n",
    "- Middle 3x3 conv processes 64 channels:  \n",
    "  \\(64 * 64 * 3 * 3 + 64 = 36,928\\) parameters.  \n",
    "- Last 1x1 conv restores dimensions to 256:  \n",
    "  \\(64 * 256 * 1 * 1 + 256 = 16,640\\) parameters.  \n",
    "- **Total**: \\(16,448 + 36,928 + 16,640 = 70,016\\) parameters.\n",
    "\n",
    "**Comparison**:\n",
    "The bottleneck block has significantly fewer parameters (70,016) compared to the regular block (1,180,160).\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Number of Floating Point Operations (FLOPs)**\n",
    "\n",
    "**Regular Block**:\n",
    "- Each 3x3 convolution involves:  \n",
    "  \\(H * W * \\text{Input Channels} * \\text{Output Channels} * 3 * 3\\).  \n",
    "- For an input size of \\(56 * 56\\):  \n",
    "  - First conv FLOPs: \\(56 * 56 * 256 * 256 * 9 = 18,475,008\\).  \n",
    "  - Second conv FLOPs: Same as above.  \n",
    "  - **Total**: \\(18,475,008 + 18,475,008 = 36,950,016\\).\n",
    "\n",
    "**Bottleneck Block**:\n",
    "- First 1x1 conv FLOPs:  \n",
    "  \\(56 * 56 * 256 * 64 = 917,504\\).  \n",
    "- Middle 3x3 conv FLOPs:  \n",
    "  \\(56 * 56 * 64 * 64 * 9 = 1,835,008\\).  \n",
    "- Last 1x1 conv FLOPs:  \n",
    "  \\(56 * 56 * 64 * 256 = 917,504\\).  \n",
    "- **Total**: \\(917,504 + 1,835,008 + 917,504 = 3,670,016\\).\n",
    "\n",
    "**Comparison**:\n",
    "The bottleneck block requires far fewer FLOPs (3,670,016) compared to the regular block (36,950,016).\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Ability to Combine Inputs**\n",
    "\n",
    "**Regular Block**:\n",
    "- **Spatial Combination**: Two 3x3 convolutions provide a larger effective receptive field (5 * 5), enhancing spatial learning.  \n",
    "- **Across Feature Maps**: Processes all 256 channels twice, allowing strong inter-feature map interactions.\n",
    "\n",
    "**Bottleneck Block**:\n",
    "- **Spatial Combination**: Only the middle 3x3 convolution contributes to spatial learning, with a smaller receptive field (3 * 3).  \n",
    "- **Across Feature Maps**: 1x1 convolutions excel at reducing and restoring dimensions, allowing efficient feature map interactions without excessive computations.\n",
    "\n",
    "---\n",
    "\n",
    "The bottleneck block is a computationally efficient alternative, trading off some spatial and feature map interactions for reduced parameters and FLOPs, which makes it ideal for deeper networks like ResNet-50 and beyond.\n",
    "\n",
    "**Regular Block**:\n",
    "- **Spatial Combination**: Two 3x3 convolutions provide a larger effective receptive field (\\(5 \\times 5\\)), enhancing spatial learning.  \n",
    "- **Across Feature Maps**: Processes all 256 channels twice, allowing strong inter-feature map interactions.\n",
    "\n",
    "**Bottleneck Block**:\n",
    "- **Spatial Combination**: Only the middle 3x3 convolution contributes to spatial learning, with a smaller receptive field (\\(3 \\times 3\\)).  \n",
    "- **Across Feature Maps**: 1x1 convolutions excel at reducing and restoring dimensions, allowing efficient feature map interactions without excessive computations.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Summary Table**\n",
    "\n",
    "| Metric                         | Regular Block                | Bottleneck Block          |\n",
    "|--------------------------------|-----------------------------|---------------------------|\n",
    "| **Parameters**                 | \\(1,180,160\\)               | \\(70,016\\)                |\n",
    "| **FLOPs**                      | \\(36,950,016\\)              | \\(3,670,016\\)             |\n",
    "| **Spatial Combination**        | Strong (\\(5 \\times 5\\))      | Moderate (\\(3 \\times 3\\)) |\n",
    "| **Feature Map Interaction**    | Extensive                   | Efficient via 1x1 convs   |\n",
    "\n",
    "The bottleneck block is a computationally efficient alternative, trading off some spatial and feature map interactions for reduced parameters and FLOPs, which makes it ideal for deeper networks like ResNet-50 and beyond."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0491f4eb8a104c789a5665f7b30ab4f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0969e7ac09e54d359b19cd42306378cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0ec72ef8cd7045c7982b11741953703a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_aec5e142021648979a92700e71bdcf66",
        "IPY_MODEL_b0342c5521574bda93c365f03af95355",
        "IPY_MODEL_7e150e5ca8534b998e2a8d8ec41a3b4e"
       ],
       "layout": "IPY_MODEL_fbb80f8431f644f187aca2bb075a0aa7"
      }
     },
     "0f958161caad42339e5917ab388848b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c7be0c86b1f548d7a9028d2026502510",
        "IPY_MODEL_1e44e57884444ce88064e0568ae5bab9",
        "IPY_MODEL_5845d72e9fea4394bd5acad16c902e9c"
       ],
       "layout": "IPY_MODEL_4bcef3d375d64c6f8380cd6623bcf0fe"
      }
     },
     "15edc15bed394b18a0bc612726d39e87": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "186fb7828917488595a76b4fb502e705": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1c9c5c63f9984847bf7b8518328acbf8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1e44e57884444ce88064e0568ae5bab9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4bc89176a4f74223aca4507d5d27f110",
       "max": 25,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f3b5af288556475a9f242a74d538cdf2",
       "value": 25
      }
     },
     "1fe84300878845b0a34f1ebeb9717f98": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2d7228d41a3e4186b1272d25d65daa9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "30b98988ad0a4850b91a10557fe5e167": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "30b9d1009a6c4b8c8c1e5a8a1e8084d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c3713572bb93415fba466c6e70809fbd",
       "placeholder": "​",
       "style": "IPY_MODEL_15edc15bed394b18a0bc612726d39e87",
       "value": " 25/25 [00:00&lt;00:00, 104.06it/s]"
      }
     },
     "375f11ccef954e7baa2299de28694ba8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "391ac21769234a07b6e358c96ab80d99": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c7fc9ef1964e436aaba037f3ec78a90b",
       "placeholder": "​",
       "style": "IPY_MODEL_1c9c5c63f9984847bf7b8518328acbf8",
       "value": " 25/25 [00:00&lt;00:00, 98.49it/s]"
      }
     },
     "39c46b94ec184d5a876ee991483d4944": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "41a2cee4192e4803923895229ec1e013": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4bc89176a4f74223aca4507d5d27f110": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4bcef3d375d64c6f8380cd6623bcf0fe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4f4182fea4c44d0694f2e308ac9eb09f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5845d72e9fea4394bd5acad16c902e9c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ee7d285c78db4c859813a72e52120386",
       "placeholder": "​",
       "style": "IPY_MODEL_8b12f927fc6649e0b2e9308a21f7796e",
       "value": " 25/25 [00:00&lt;00:00, 115.70it/s]"
      }
     },
     "5bd74e6f659c4d4d9089b6dec5a09599": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_acc45a870cca4f7b9a60fe1146bc07ab",
        "IPY_MODEL_c2192e810aa448a9b44a6a45cdc9ab7e",
        "IPY_MODEL_391ac21769234a07b6e358c96ab80d99"
       ],
       "layout": "IPY_MODEL_0491f4eb8a104c789a5665f7b30ab4f9"
      }
     },
     "723404fb7a954c4991cf0d3502b3d7dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_39c46b94ec184d5a876ee991483d4944",
       "max": 25,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_41a2cee4192e4803923895229ec1e013",
       "value": 25
      }
     },
     "76c12a0030094fcda169de17d30ff123": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_375f11ccef954e7baa2299de28694ba8",
       "placeholder": "​",
       "style": "IPY_MODEL_96da83b0f3ea4c47ad862785ae9b3b92",
       "value": "train_batch (Avg. Loss 0.773, Accuracy 74.0): 100%"
      }
     },
     "772e4f6a006042a3a5375731324cb921": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "785296ca81cd429fb8c04a34fff51b93": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7e150e5ca8534b998e2a8d8ec41a3b4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_80adafd5f23f43aeb5c32fa23e41113d",
       "placeholder": "​",
       "style": "IPY_MODEL_1fe84300878845b0a34f1ebeb9717f98",
       "value": " 25/25 [00:00&lt;00:00, 122.97it/s]"
      }
     },
     "7f2de78a5f7d44e4bae7a18a67649cc6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "80adafd5f23f43aeb5c32fa23e41113d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8b12f927fc6649e0b2e9308a21f7796e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "94732ec289ea4e44a85d7b4676526ca8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "96da83b0f3ea4c47ad862785ae9b3b92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9bf56f050c4945b0891b68301b43247b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a4db52476895483f8bc9ff3416247a3d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a6d378282d8e47558f8a48ea5ef3636b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "acc45a870cca4f7b9a60fe1146bc07ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f15d7b3009684a159153c1e03a4b3ed2",
       "placeholder": "​",
       "style": "IPY_MODEL_7f2de78a5f7d44e4bae7a18a67649cc6",
       "value": "train_batch (Avg. Loss 2.371, Accuracy 6.0): 100%"
      }
     },
     "ad6fbeae58054e6a9ec36716f44b2b33": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aec5e142021648979a92700e71bdcf66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_772e4f6a006042a3a5375731324cb921",
       "placeholder": "​",
       "style": "IPY_MODEL_0969e7ac09e54d359b19cd42306378cf",
       "value": "train_batch (Avg. Loss 1.149, Accuracy 56.0): 100%"
      }
     },
     "b0342c5521574bda93c365f03af95355": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a6d378282d8e47558f8a48ea5ef3636b",
       "max": 25,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a4db52476895483f8bc9ff3416247a3d",
       "value": 25
      }
     },
     "b463f90c1b014548b5d23333e0dc4803": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c2192e810aa448a9b44a6a45cdc9ab7e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c4c3decc15764901bea67f09780eeed6",
       "max": 25,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_785296ca81cd429fb8c04a34fff51b93",
       "value": 25
      }
     },
     "c3713572bb93415fba466c6e70809fbd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c4c3decc15764901bea67f09780eeed6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c7be0c86b1f548d7a9028d2026502510": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_186fb7828917488595a76b4fb502e705",
       "placeholder": "​",
       "style": "IPY_MODEL_9bf56f050c4945b0891b68301b43247b",
       "value": "train_batch (Avg. Loss 1.963, Accuracy 26.0): 100%"
      }
     },
     "c7fc9ef1964e436aaba037f3ec78a90b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cbef240ba30746a3827d3747ef381c67": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_76c12a0030094fcda169de17d30ff123",
        "IPY_MODEL_e3950120b7db465dbfee859677b111ed",
        "IPY_MODEL_30b9d1009a6c4b8c8c1e5a8a1e8084d4"
       ],
       "layout": "IPY_MODEL_94732ec289ea4e44a85d7b4676526ca8"
      }
     },
     "df5f65c8d4e14535bc011b689ea70c70": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e3950120b7db465dbfee859677b111ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e39b9d6f425641dfbeb8b6bbc49aa40a",
       "max": 25,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4f4182fea4c44d0694f2e308ac9eb09f",
       "value": 25
      }
     },
     "e39b9d6f425641dfbeb8b6bbc49aa40a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e772d09dba434d4ea46d22e34dd214c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b463f90c1b014548b5d23333e0dc4803",
       "placeholder": "​",
       "style": "IPY_MODEL_2d7228d41a3e4186b1272d25d65daa9f",
       "value": " 25/25 [00:00&lt;00:00, 112.94it/s]"
      }
     },
     "ee7d285c78db4c859813a72e52120386": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f15d7b3009684a159153c1e03a4b3ed2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f3b5af288556475a9f242a74d538cdf2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f3fd683d980846ab80965298c6c00c7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fbfc41a89a28446dbbfa4cec20d94faa",
        "IPY_MODEL_723404fb7a954c4991cf0d3502b3d7dd",
        "IPY_MODEL_e772d09dba434d4ea46d22e34dd214c2"
       ],
       "layout": "IPY_MODEL_df5f65c8d4e14535bc011b689ea70c70"
      }
     },
     "fbb80f8431f644f187aca2bb075a0aa7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fbfc41a89a28446dbbfa4cec20d94faa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ad6fbeae58054e6a9ec36716f44b2b33",
       "placeholder": "​",
       "style": "IPY_MODEL_30b98988ad0a4850b91a10557fe5e167",
       "value": "train_batch (Avg. Loss 0.141, Accuracy 94.0): 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
